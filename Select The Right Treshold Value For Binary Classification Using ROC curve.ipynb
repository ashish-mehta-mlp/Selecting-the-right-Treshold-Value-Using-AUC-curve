{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treshold Value\n",
    "\n",
    "- During binary classification like Logistic Regression, if we get the output probabilty above 0.5, then it is considered as 1 and if the output probability is below 0.5 it is considerd as 0.\n",
    "- This 0.5 is the Treshold value. Based on our problem statement and our dataset, we can also change the treshold Value.\n",
    "- We come to know what is the best treshold value using ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# roc curve and auc score\n",
    "from sklearn.datasets import make_classification # This library is used to create a new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X,y = make_classification(n_samples=2000, n_classes=2, weights=[1,1], random_state=1)\n",
    "\n",
    "# n_samples = number of rows\n",
    "# n_classes = number of output classes (2 - Binary classification)\n",
    "# weights = 1,1 means balanced dataset. Equal number of 0 and 1 in the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 20), (2000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF train roc-auc: 0.9999999999999999\n",
      "RF test roc-auc: 0.9806444444444444\n"
     ]
    }
   ],
   "source": [
    "## Apply RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "ytrain_pred = rf_model.predict_proba(X_train)\n",
    "print('RF train roc-auc: {}'.format(roc_auc_score(y_train, ytrain_pred[:,1])))\n",
    "ytest_pred = rf_model.predict_proba(X_test)\n",
    "print('RF test roc-auc: {}'.format(roc_auc_score(y_test, ytest_pred[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here, we are predicting on the training data (X_train) itself. Hence the first accuracy is very high\n",
    "- We have used predict_proba. Hence it will give 2 colums. Probability of 0 and Probability of 1\n",
    "- We have chosen any one probability for ROC AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99, 0.01],\n",
       "       [0.99, 0.01],\n",
       "       [0.02, 0.98],\n",
       "       ...,\n",
       "       [0.99, 0.01],\n",
       "       [0.98, 0.02],\n",
       "       [0.3 , 0.7 ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic train roc-auc: 0.9863568922694498\n",
      "Logistic test roc-auc: 0.9885777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_classifier=LogisticRegression()\n",
    "log_classifier.fit(X_train, y_train)\n",
    "ytrain_pred = log_classifier.predict_proba(X_train)\n",
    "print('Logistic train roc-auc: {}'.format(roc_auc_score(y_train, ytrain_pred[:,1])))\n",
    "ytest_pred = log_classifier.predict_proba(X_test)\n",
    "print('Logistic test roc-auc: {}'.format(roc_auc_score(y_test, ytest_pred[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost train roc-auc: 0.9975081174960356\n",
      "Adaboost test roc-auc: 0.9826111111111111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_classifier=AdaBoostClassifier()\n",
    "ada_classifier.fit(X_train, y_train)\n",
    "ytrain_pred = ada_classifier.predict_proba(X_train)\n",
    "print('Adaboost train roc-auc: {}'.format(roc_auc_score(y_train, ytrain_pred[:,1])))\n",
    "ytest_pred = ada_classifier.predict_proba(X_test)\n",
    "print('Adaboost test roc-auc: {}'.format(roc_auc_score(y_test, ytest_pred[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost train roc-auc: 0.981670071491109\n",
      "Adaboost test roc-auc: 0.9426111111111111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_classifier=KNeighborsClassifier()\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "ytrain_pred = knn_classifier.predict_proba(X_train)\n",
    "print('Adaboost train roc-auc: {}'.format(roc_auc_score(y_train, ytrain_pred[:,1])))\n",
    "ytest_pred = knn_classifier.predict_proba(X_test)\n",
    "print('Adaboost test roc-auc: {}'.format(roc_auc_score(y_test, ytest_pred[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will Focus of Best Treshold to get the Maximum Accuracy\n",
    "\n",
    "- By default, the treshold value is selected as 0.5\n",
    "- We have to get the best treshold value for maximum accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble test roc-auc: 0.9847444444444444\n"
     ]
    }
   ],
   "source": [
    "# We will be combining all the 4 models that we have previously created\n",
    "\n",
    "pred=[]\n",
    "for model in [rf_model,log_classifier,ada_classifier,knn_classifier]:\n",
    "    pred.append(pd.Series(model.predict_proba(X_test)[:,1])) # here, we are column wise appending probabilities of any one class (0 or 1) for X_test for all the 4 models\n",
    "final_prediction=pd.concat(pred,axis=1).mean(axis=1) # We are creating a new dataset which takes row wise average of all the probabilities\n",
    "print('Ensemble test roc-auc: {}'.format(roc_auc_score(y_test,final_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.991861</td>\n",
       "      <td>0.559186</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.463282</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.966929</td>\n",
       "      <td>0.538202</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.761539</td>\n",
       "      <td>0.509875</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.779443</td>\n",
       "      <td>0.490344</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.544222</td>\n",
       "      <td>0.492548</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.977857</td>\n",
       "      <td>0.537171</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.960771</td>\n",
       "      <td>0.552570</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.993640</td>\n",
       "      <td>0.537610</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.505748</td>\n",
       "      <td>0.510507</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.863536</td>\n",
       "      <td>0.512212</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.819844</td>\n",
       "      <td>0.516065</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.081238</td>\n",
       "      <td>0.482698</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.902638</td>\n",
       "      <td>0.522522</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.929639</td>\n",
       "      <td>0.540503</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.471953</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.010452</td>\n",
       "      <td>0.449861</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.008408</td>\n",
       "      <td>0.461462</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.452186</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.472297</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.997154</td>\n",
       "      <td>0.580102</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.572811</td>\n",
       "      <td>0.502760</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.959655</td>\n",
       "      <td>0.529753</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.916288</td>\n",
       "      <td>0.525194</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>0.468808</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.988646</td>\n",
       "      <td>0.536384</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.003399</td>\n",
       "      <td>0.472655</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.915578</td>\n",
       "      <td>0.516544</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.994005</td>\n",
       "      <td>0.465189</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.173908</td>\n",
       "      <td>0.487888</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.988901</td>\n",
       "      <td>0.560456</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.484082</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.935658</td>\n",
       "      <td>0.526470</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.096163</td>\n",
       "      <td>0.488249</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.004886</td>\n",
       "      <td>0.436986</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.988274</td>\n",
       "      <td>0.537301</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.064239</td>\n",
       "      <td>0.472420</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.462387</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.179135</td>\n",
       "      <td>0.481436</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.456487</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.503867</td>\n",
       "      <td>0.488149</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.014155</td>\n",
       "      <td>0.460077</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.022498</td>\n",
       "      <td>0.462516</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.460067</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.380438</td>\n",
       "      <td>0.472308</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.926243</td>\n",
       "      <td>0.530210</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.005095</td>\n",
       "      <td>0.453253</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.992214</td>\n",
       "      <td>0.641799</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.458497</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.041835</td>\n",
       "      <td>0.476963</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.432176</td>\n",
       "      <td>0.502398</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>0.464514</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.443043</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>0.458305</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.467070</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.024239</td>\n",
       "      <td>0.461121</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.441377</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.984385</td>\n",
       "      <td>0.532403</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.441720</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.989540</td>\n",
       "      <td>0.559890</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2    3\n",
       "0    0.96  0.991861  0.559186  1.0\n",
       "1    0.01  0.000008  0.463282  0.0\n",
       "2    0.96  0.966929  0.538202  0.8\n",
       "3    0.95  0.761539  0.509875  0.8\n",
       "4    0.61  0.779443  0.490344  0.4\n",
       "5    0.27  0.544222  0.492548  0.6\n",
       "6    0.96  0.977857  0.537171  1.0\n",
       "7    0.91  0.960771  0.552570  0.8\n",
       "8    0.98  0.993640  0.537610  1.0\n",
       "9    0.66  0.505748  0.510507  0.6\n",
       "10   0.78  0.863536  0.512212  0.6\n",
       "11   0.78  0.819844  0.516065  0.6\n",
       "12   0.02  0.081238  0.482698  0.2\n",
       "13   0.89  0.902638  0.522522  1.0\n",
       "14   0.94  0.929639  0.540503  1.0\n",
       "15   0.07  0.000101  0.471953  0.0\n",
       "16   0.01  0.010452  0.449861  0.2\n",
       "17   0.00  0.008408  0.461462  0.0\n",
       "18   0.01  0.000173  0.452186  0.0\n",
       "19   0.03  0.000384  0.472297  0.0\n",
       "20   0.99  0.997154  0.580102  1.0\n",
       "21   0.49  0.572811  0.502760  0.6\n",
       "22   0.78  0.959655  0.529753  0.8\n",
       "23   0.96  0.916288  0.525194  0.8\n",
       "24   0.02  0.000910  0.468808  0.0\n",
       "25   1.00  0.988646  0.536384  0.8\n",
       "26   0.10  0.003399  0.472655  0.0\n",
       "27   0.93  0.915578  0.516544  0.6\n",
       "28   0.67  0.994005  0.465189  0.8\n",
       "29   0.32  0.173908  0.487888  0.8\n",
       "..    ...       ...       ...  ...\n",
       "570  0.98  0.988901  0.560456  1.0\n",
       "571  0.00  0.000049  0.484082  0.0\n",
       "572  0.97  0.935658  0.526470  0.6\n",
       "573  0.10  0.096163  0.488249  0.6\n",
       "574  0.03  0.004886  0.436986  0.0\n",
       "575  0.93  0.988274  0.537301  0.8\n",
       "576  0.06  0.064239  0.472420  0.2\n",
       "577  0.05  0.000003  0.462387  0.0\n",
       "578  0.26  0.179135  0.481436  0.8\n",
       "579  0.02  0.000014  0.456487  0.0\n",
       "580  0.52  0.503867  0.488149  0.8\n",
       "581  0.09  0.014155  0.460077  0.2\n",
       "582  0.07  0.022498  0.462516  0.2\n",
       "583  0.02  0.000693  0.460067  0.0\n",
       "584  0.27  0.380438  0.472308  0.4\n",
       "585  0.85  0.926243  0.530210  1.0\n",
       "586  0.01  0.005095  0.453253  0.2\n",
       "587  0.95  0.992214  0.641799  1.0\n",
       "588  0.03  0.000078  0.458497  0.0\n",
       "589  0.16  0.041835  0.476963  0.4\n",
       "590  0.65  0.432176  0.502398  0.8\n",
       "591  0.02  0.002409  0.464514  0.2\n",
       "592  0.01  0.001031  0.443043  0.0\n",
       "593  0.02  0.005882  0.458305  0.4\n",
       "594  0.01  0.000794  0.467070  0.0\n",
       "595  0.01  0.024239  0.461121  0.0\n",
       "596  0.01  0.000003  0.441377  0.0\n",
       "597  0.98  0.984385  0.532403  1.0\n",
       "598  0.03  0.001147  0.441720  0.2\n",
       "599  1.00  0.989540  0.559890  0.8\n",
       "\n",
       "[600 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.877762\n",
       "1      0.118323\n",
       "2      0.816283\n",
       "3      0.755353\n",
       "4      0.569947\n",
       "5      0.476693\n",
       "6      0.868757\n",
       "7      0.805835\n",
       "8      0.877812\n",
       "9      0.569064\n",
       "10     0.688937\n",
       "11     0.678977\n",
       "12     0.195984\n",
       "13     0.828790\n",
       "14     0.852536\n",
       "15     0.135514\n",
       "16     0.167578\n",
       "17     0.117468\n",
       "18     0.115590\n",
       "19     0.125670\n",
       "20     0.891814\n",
       "21     0.541393\n",
       "22     0.767352\n",
       "23     0.800371\n",
       "24     0.122429\n",
       "25     0.831257\n",
       "26     0.144014\n",
       "27     0.740531\n",
       "28     0.732298\n",
       "29     0.445449\n",
       "         ...   \n",
       "570    0.882339\n",
       "571    0.121033\n",
       "572    0.758032\n",
       "573    0.321103\n",
       "574    0.117968\n",
       "575    0.813894\n",
       "576    0.199165\n",
       "577    0.128098\n",
       "578    0.430143\n",
       "579    0.119125\n",
       "580    0.578004\n",
       "581    0.191058\n",
       "582    0.188754\n",
       "583    0.120190\n",
       "584    0.380687\n",
       "585    0.826613\n",
       "586    0.167087\n",
       "587    0.896003\n",
       "588    0.122144\n",
       "589    0.269699\n",
       "590    0.596143\n",
       "591    0.171731\n",
       "592    0.113518\n",
       "593    0.221047\n",
       "594    0.119466\n",
       "595    0.123840\n",
       "596    0.112845\n",
       "597    0.874197\n",
       "598    0.168217\n",
       "599    0.837357\n",
       "Length: 600, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.91174686, 0.91174686, 0.90623256, 0.90577475, 0.80056516,\n",
       "       0.8005558 , 0.79381489, 0.79162833, 0.78877646, 0.78821156,\n",
       "       0.77047605, 0.76787124, 0.74391018, 0.74387362, 0.69294088,\n",
       "       0.68893711, 0.67268151, 0.67243537, 0.60988185, 0.58736186,\n",
       "       0.5790152 , 0.57800386, 0.55792732, 0.55719563, 0.55149047,\n",
       "       0.54139283, 0.52605932, 0.49866892, 0.4471034 , 0.39475652,\n",
       "       0.38129719, 0.35268074, 0.34836612, 0.23719741, 0.23396893,\n",
       "       0.19782943, 0.19598417, 0.12545384, 0.1253351 , 0.10695344])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Calculate the ROc Curve\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, final_prediction)\n",
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thresholds</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.447103</td>\n",
       "      <td>0.961667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.498669</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.526059</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.541393</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.551490</td>\n",
       "      <td>0.956667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    thresholds  accuracy\n",
       "28    0.447103  0.961667\n",
       "27    0.498669  0.958333\n",
       "26    0.526059  0.958333\n",
       "25    0.541393  0.958333\n",
       "24    0.551490  0.956667"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_ls = []\n",
    "for thres in thresholds:\n",
    "    y_pred = np.where(final_prediction>thres,1,0)\n",
    "    accuracy_ls.append(accuracy_score(y_test, y_pred, normalize=True))\n",
    "    \n",
    "accuracy_ls = pd.concat([pd.Series(thresholds), pd.Series(accuracy_ls)],\n",
    "                        axis=1)\n",
    "accuracy_ls.columns = ['thresholds', 'accuracy']\n",
    "accuracy_ls.sort_values(by='accuracy', ascending=False, inplace=True)\n",
    "accuracy_ls.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see that Treshold Value of 0.447103 gives the highest Accuracy. Hence that Treshold will be Selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
